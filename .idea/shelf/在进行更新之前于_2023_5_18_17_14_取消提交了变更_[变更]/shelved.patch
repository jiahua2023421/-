Index: public.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\r\nimport os, glob, datetime\r\nimport re\r\nimport torch\r\nfrom torch.nn.modules.loss import _Loss\r\n\r\n# 参数设置\r\ndef parse_args(flag):\r\n    if flag == 1:\r\n        # 测试\r\n        # 容器参数规范，并具有将解析器作为一个整体应用的选项\r\n        test_parser = argparse.ArgumentParser()\r\n        test_parser.add_argument('--set_dir', default='data/Test', type=str, help='directory of test dataset')\r\n        test_parser.add_argument('--set_names', default=['Set68', 'Set12'], help='directory of test dataset')\r\n        test_parser.add_argument('--sigma', default=25, type=int, help='noise level')\r\n        test_parser.add_argument('--model_dir', default=os.path.join('models', 'DnCNN_sigma25'), help='directory of the model')\r\n        # os.path.join  路径拼接\r\n        test_parser.add_argument('--model_name', default='model_001.pth', type=str, help='the model name')\r\n        test_parser.add_argument('--result_dir', default='results', type=str, help='directory of test dataset')\r\n        test_parser.add_argument('--save_result', default=0, type=int, help='save the denoised image, 1 or 0')\r\n        return test_parser.parse_args()\r\n    else:\r\n        # 训练\r\n        train_parser = argparse.ArgumentParser(description='PyTorch DnCNN')\r\n        train_parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\r\n        train_parser.add_argument('--batch_size', default=64, type=int, help='batch size')\r\n        train_parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\r\n        train_parser.add_argument('--sigma', default=25, type=int, help='noise level')\r\n        train_parser.add_argument('--epoch', default=180, type=int, help='number of train epoches')\r\n        train_parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\r\n        return train_parser.parse_args()\r\n\r\n\r\n# 测试点\r\ndef findLastCheckpoint(save_dir):\r\n    file_list = glob.glob(os.path.join(save_dir, 'model_*.pth'))\r\n    if file_list:\r\n        epochs_exist = []\r\n        for file_ in file_list:\r\n            result = re.findall(\".*model_(.*).pth.*\", file_)\r\n            epochs_exist.append(int(result[0]))\r\n        initial_epoch = max(epochs_exist)\r\n    else:\r\n        initial_epoch = 0\r\n    return initial_epoch\r\n\r\n# 日志\r\ndef log(*args, **kwargs):\r\n    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\r\n\r\n# 计算损失\r\nclass sum_squared_error(_Loss):  # PyTorch 0.4.1\r\n    \"\"\"\r\n    Definition: sum_squared_error = 1/2 * nn.MSELoss(reduction = 'sum')\r\n    The backward is defined as: input-target\r\n    \"\"\"\r\n    def __init__(self, size_average=None, reduce=None, reduction='sum'):\r\n        super(sum_squared_error, self).__init__(size_average, reduce, reduction)\r\n\r\n    def forward(self, input, target):\r\n        # return torch.sum(torch.pow(input-target,2), (0,1,2,3)).div_(2)\r\n        return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/public.py b/public.py
--- a/public.py	(revision 777293bac1d1ea9c986accfd68dc7b620cdaf704)
+++ b/public.py	(date 1684398878577)
@@ -23,7 +23,7 @@
         # 训练
         train_parser = argparse.ArgumentParser(description='PyTorch DnCNN')
         train_parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')
-        train_parser.add_argument('--batch_size', default=64, type=int, help='batch size')
+        train_parser.add_argument('--batch_size', default=128, type=int, help='batch size')
         train_parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')
         train_parser.add_argument('--sigma', default=25, type=int, help='noise level')
         train_parser.add_argument('--epoch', default=180, type=int, help='number of train epoches')
Index: train.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 官方库\r\nimport torch, os, time\r\nimport torch.optim as optim\r\nimport numpy as np\r\nfrom torch.optim.lr_scheduler import MultiStepLR\r\nfrom torch.utils.data import DataLoader\r\n# 私人库\r\nfrom model import DnCNN\r\nfrom public import findLastCheckpoint, parse_args, sum_squared_error, log\r\nimport data_process as dp\r\nfrom data_process import DenoisingDataset\r\n\r\nif __name__ == '__main__':\r\n    # 加载模型\r\n    model = DnCNN()\r\n    # 参数初始化\r\n    # 运行解析器并放置提取的数据在 argparse.Namespace 对象\r\n    args = parse_args(0)\r\n    batch_size = args.batch_size\r\n    cuda = torch.cuda.is_available()\r\n    n_epoch = args.epoch\r\n    sigma = args.sigma\r\n    # 保存模型路径\r\n    save_dir = os.path.join('models', args.model + '_' + 'sigma' + str(sigma))\r\n    if not os.path.exists(save_dir):\r\n        os.mkdir(save_dir)\r\n\r\n    initial_epoch = findLastCheckpoint(save_dir=save_dir)  # load the last model in matconvnet style\r\n    if initial_epoch > 0:\r\n        print('resuming by loading epoch %03d' % initial_epoch)\r\n        # model.load_state_dict(torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch)))\r\n        model = torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch))\r\n    model.train()\r\n    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\r\n    criterion = sum_squared_error()\r\n    # GPU or CPU\r\n    if cuda:\r\n        model = model.cuda()\r\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\r\n    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)  # learning rates\r\n    # 训练\r\n    for epoch in range(initial_epoch, n_epoch):\r\n        scheduler.step(epoch)  # step to the learning rate in this epcoh\r\n        xs = dp.datagenerator(data_dir=args.train_data)\r\n        xs = xs.astype('float32') / 255.0\r\n        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\r\n        DDataset = DenoisingDataset(xs, sigma)\r\n        DLoader = DataLoader(dataset=DDataset, num_workers=1, drop_last=True, batch_size=batch_size, shuffle=True)\r\n        epoch_loss = 0\r\n        start_time = time.time()\r\n\r\n        for n_count, batch_yx in enumerate(DLoader):\r\n            optimizer.zero_grad()\r\n            if cuda:\r\n                batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\r\n            # loss = criterion(model(batch_yx[0]), batch_yx[1])\r\n            loss = criterion(model(batch_y), batch_x)\r\n            epoch_loss += loss.item()\r\n            loss.backward()\r\n            optimizer.step()\r\n            if n_count % 10 == 0:\r\n                print('%4d %4d / %4d loss = %2.4f' % (\r\n                epoch + 1, n_count, xs.size(0) // batch_size, loss.item() / batch_size))\r\n        elapsed_time = time.time() - start_time\r\n\r\n        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch + 1, epoch_loss / n_count, elapsed_time))\r\n        np.savetxt('train_result.txt', np.hstack((epoch + 1, epoch_loss / n_count, elapsed_time)), fmt='%2.4f')\r\n        # torch.save(model.state_dict(), os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\r\n        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch + 1)))
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train.py b/train.py
--- a/train.py	(revision 777293bac1d1ea9c986accfd68dc7b620cdaf704)
+++ b/train.py	(date 1684397565261)
@@ -53,8 +53,8 @@
             optimizer.zero_grad()
             if cuda:
                 batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()
-            # loss = criterion(model(batch_yx[0]), batch_yx[1])
-            loss = criterion(model(batch_y), batch_x)
+            loss = criterion(model(batch_yx[0]), batch_yx[1])
+            # loss = criterion(model(batch_y), batch_x)
             epoch_loss += loss.item()
             loss.backward()
             optimizer.step()
Index: test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 官方库\r\nimport torch, os, time\r\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\r\nimport numpy as np\r\nfrom imageio import imread\r\nfrom skimage.metrics import structural_similarity as compare_ssim\r\nfrom skimage.metrics import peak_signal_noise_ratio as compare_psnr\r\n# 私人库\r\nfrom public import parse_args, log\r\nfrom data_process import show, save_result\r\nfrom model import DnCNN\r\n\r\nif __name__ == '__main__':\r\n    # 参数\r\n    args = parse_args(1)\r\n\r\n    # 加载模型\r\n    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):  # model_001若不存在，则加载model\r\n        model = torch.load(os.path.join(args.model_dir, 'model.pth'), map_location='cpu')  # 映射到CPU\r\n        log('load trained model on Train400 dataset by kai')\r\n    else:\r\n        model = torch.load(os.path.join(args.model_dir, args.model_name), map_location='cpu')\r\n        log('load trained model')\r\n\r\n    model.eval()  # evaluation mode  设置为预测模式\r\n\r\n    # GPU or CPU\r\n    #    if torch.cuda.is_available():  #GPU\r\n    #        model = model.cuda()\r\n\r\n    # 保存路径\r\n    if not os.path.exists(args.result_dir):  # 结果路径\r\n        os.mkdir(args.result_dir)  # 创造目录\r\n\r\n    # 测试图片保存\r\n    for set_cur in args.set_names:\r\n        if not os.path.exists(os.path.join(args.result_dir, set_cur)):\r\n            os.mkdir(os.path.join(args.result_dir, set_cur))\r\n        psnrs = []\r\n        ssims = []\r\n\r\n        for im in os.listdir(os.path.join(args.set_dir, set_cur)):  # 返回指定的文件夹包含的文件或文件夹的名字的列表\r\n            if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\r\n                x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32) / 255.0\r\n                #  dtype:数组中的数据类型\r\n                np.random.seed(seed=0)  # for reproducibility\r\n                y = x + np.random.normal(0, args.sigma / 255.0, x.shape)  # Add Gaussian noise without clipping\r\n                y = y.astype(np.float32)\r\n                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\r\n\r\n                torch.cuda.synchronize()\r\n                start_time = time.time()\r\n                #               y_ = y_.cuda()\r\n                x_ = model(y_)  # inference\r\n                x_ = x_.view(y.shape[0], y.shape[1])\r\n                x_ = x_.cpu()\r\n                x_ = x_.detach().numpy().astype(np.float32)\r\n                torch.cuda.synchronize()\r\n                elapsed_time = time.time() - start_time\r\n                print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\r\n\r\n                psnr_x_ = compare_psnr(x, x_)\r\n                ssim_x_ = compare_ssim(x, x_)\r\n                # if args.save_result:\r\n                name, ext = os.path.splitext(im)\r\n                show(np.hstack((y, x_)))  # show the image\r\n                save_result(x_, path=os.path.join(args.result_dir, set_cur,\r\n                                                  name + '_dncnn' + ext))  # save the denoised image\r\n                psnrs.append(psnr_x_)\r\n                ssims.append(ssim_x_)\r\n        psnr_avg = np.mean(psnrs)\r\n        ssim_avg = np.mean(ssims)\r\n        psnrs.append(psnr_avg)\r\n        ssims.append(ssim_avg)\r\n        # if args.save_result:\r\n        save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\r\n        log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/test.py b/test.py
--- a/test.py	(revision 777293bac1d1ea9c986accfd68dc7b620cdaf704)
+++ b/test.py	(date 1684396381792)
@@ -5,7 +5,8 @@
 from imageio import imread
 from skimage.metrics import structural_similarity as compare_ssim
 from skimage.metrics import peak_signal_noise_ratio as compare_psnr
-# 私人库
+ # 私人库
+
 from public import parse_args, log
 from data_process import show, save_result
 from model import DnCNN
@@ -48,19 +49,22 @@
                 y = y.astype(np.float32)
                 y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])
 
-                torch.cuda.synchronize()
+                # torch.cuda.synchronize()
                 start_time = time.time()
                 #               y_ = y_.cuda()
                 x_ = model(y_)  # inference
                 x_ = x_.view(y.shape[0], y.shape[1])
                 x_ = x_.cpu()
                 x_ = x_.detach().numpy().astype(np.float32)
-                torch.cuda.synchronize()
-                elapsed_time = time.time() - start_time
-                print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))
+                # torch.cuda.synchronize()
+                # elapsed_time = time.time() - start_time
+                # print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))
 
                 psnr_x_ = compare_psnr(x, x_)
                 ssim_x_ = compare_ssim(x, x_)
+
+                ssim_x_ = compare_ssim(x, x_)
+
                 # if args.save_result:
                 name, ext = os.path.splitext(im)
                 show(np.hstack((y, x_)))  # show the image
@@ -72,6 +76,6 @@
         ssim_avg = np.mean(ssims)
         psnrs.append(psnr_avg)
         ssims.append(ssim_avg)
-        # if args.save_result:
-        save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))
+        if args.save_result:
+         save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))
         log('Datset: {0:10s} \n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))
\ No newline at end of file
