Index: train.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 官方库\r\nimport torch, os, time\r\nimport torch.optim as optim\r\nimport numpy as np\r\nfrom torch.optim.lr_scheduler import MultiStepLR\r\nfrom torch.utils.data import DataLoader\r\n# 私人库\r\nfrom model import DnCNN\r\nfrom public import findLastCheckpoint, parse_args, sum_squared_error, log\r\nimport data_process as dp\r\nfrom data_process import DenoisingDataset\r\n\r\nif __name__ == '__main__':\r\n    # 加载模型\r\n    model = DnCNN()\r\n    # 参数初始化\r\n    # 运行解析器并放置提取的数据在 argparse.Namespace 对象\r\n    args = parse_args(0)\r\n    batch_size = args.batch_size\r\n    cuda = torch.cuda.is_available()\r\n    n_epoch = args.epoch\r\n    sigma = args.sigma\r\n    # 保存模型路径\r\n    save_dir = os.path.join('models', args.model + '_' + 'sigma' + str(sigma))\r\n    if not os.path.exists(save_dir):\r\n        os.mkdir(save_dir)\r\n\r\n    initial_epoch = findLastCheckpoint(save_dir=save_dir)  # load the last model in matconvnet style\r\n    if initial_epoch > 0:\r\n        print('resuming by loading epoch %03d' % initial_epoch)\r\n        # model.load_state_dict(torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch)))\r\n        model = torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch))\r\n    model.train()\r\n    # criterion = nn.MSELoss(reduction = 'sum')  # PyTorch 0.4.1\r\n    criterion = sum_squared_error()\r\n    # GPU or CPU\r\n    if cuda:\r\n        model = model.cuda()\r\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\r\n    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)  # learning rates\r\n    # 训练\r\n    # epoch = 1\r\n    for epoch in range(initial_epoch, n_epoch):\r\n        scheduler.step(epoch)  # step to the learning rate in this epcoh\r\n        xs = dp.datagenerator(data_dir=args.train_data)\r\n        xs = xs.astype('float32') / 255.0\r\n        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))  # tensor of the clean patches, NXCXHXW\r\n        DDataset = DenoisingDataset(xs, sigma)\r\n        DLoader = DataLoader(dataset=DDataset, num_workers=1, drop_last=True, batch_size=batch_size, shuffle=True)\r\n        # DLoader = DataLoader(dataset=DDataset, num_workers=1, drop_last=True, batch_size=batch_size, shuffle=False)\r\n        # dataset (Dataset) – 决定数据从哪读取或者从何读取；\r\n        # num_workers (python:int, optional) – 是否多进程读取数据（默认为０);\r\n        # drop_last (bool, optional) – 当样本数不能被batchsize整除时，最后一批数据是否舍弃（default: False)\r\n        # batchszie：批大小，决定一个epoch有多少个Iteration；\r\n        # shuffle (bool, optional) –每一个 epoch是否为乱序 (default: False)；\r\n\r\n        epoch_loss = 0\r\n        start_time = time.time()\r\n\r\n        for n_count, batch_yx in enumerate(DLoader):\r\n            optimizer.zero_grad()\r\n            if cuda:\r\n                batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\r\n            loss = criterion(model(batch_yx[0]), batch_yx[1])\r\n            # loss = criterion(model(batch_y), batch_x)\r\n            epoch_loss += loss.item()\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n            ceshi1 = xs.size(0)\r\n            ceshi = xs.size(0) // batch_size\r\n            if n_count % 10 == 0:\r\n                print('%4d %4d / %4d loss = %2.4f' % (\r\n                epoch + 1, n_count, xs.size(0) // batch_size, loss.item() / batch_size))\r\n        elapsed_time = time.time() - start_time\r\n\r\n        log('epcoh = %4d , loss = %4.4f , time = %4.2f s' % (epoch + 1, epoch_loss / n_count, elapsed_time))\r\n        np.savetxt('train_result.txt', np.hstack((epoch + 1, epoch_loss / n_count, elapsed_time)), fmt='%2.4f')\r\n        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))\r\n    # torch.save(model, os.path.join(save_dir, 'model_001.pth'))\r\n    # torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch + 1)))\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train.py b/train.py
--- a/train.py	
+++ b/train.py	
@@ -1,5 +1,7 @@
 # 官方库
-import torch, os, time
+import os
+import torch
+import time
 import torch.optim as optim
 import numpy as np
 from torch.optim.lr_scheduler import MultiStepLR
Index: test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 官方库\r\nimport torch, os, time\r\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\r\nimport numpy as np\r\nfrom imageio import imread\r\nfrom skimage.metrics import structural_similarity as compare_ssim\r\nfrom skimage.metrics import peak_signal_noise_ratio as compare_psnr\r\n # 私人库\r\n\r\nfrom public import parse_args, log\r\nfrom data_process import show, save_result\r\nfrom model import DnCNN\r\n\r\n\r\n\r\nif __name__ == '__main__':\r\n    # 参数\r\n    args = parse_args(1)  #测试集\r\n\r\n    # model = DnCNN()\r\n    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):  # model_001若不存在，则加载model\r\n\r\n        model_cpu = torch.load(os.path.join(args.model_dir, 'model.pth'), map_location='cpu')  # 映射到CPU，此模型不会被加载到cuda\r\n        model = torch.load(os.path.join(args.model_dir, 'model.pth'), map_location='cpu')  # 映射到CPU\r\n        # load weights into new model\r\n        log('load trained model on Train400 dataset by kai')  #张凯的模型\r\n    else:\r\n        # model.load_state_dict(torch.load(os.path.join(args.model_dir, args.model_name)))\r\n        model_cpu = torch.load(os.path.join(args.model_dir, args.model_name), map_location='cpu')\r\n        model = torch.load(os.path.join(args.model_dir, args.model_name), map_location='cpu')\r\n        log('load trained model')   #本地训练的模型\r\n\r\n    #    params = model.state_dict()\r\n    #    print(params.values())\r\n    #    print(params.keys())\r\n    #\r\n    #    for key, value in params.items():\r\n    #        print(key)    # parameter name\r\n    #    print(params['dncnn.12.running_mean'])\r\n    #    print(model.state_dict())\r\n\r\n    model_cpu.eval()  # evaluation mode  设置为预测模式\r\n    #    model.train()\r\n\r\n    if torch.cuda.is_available():  # GPU\r\n        model = model.cuda()  # 加载到GPU\r\n\r\n    if not os.path.exists(args.result_dir):  # 结果路径\r\n        os.mkdir(args.result_dir)  # 创造目录\r\n\r\n    for set_cur in args.set_names:  # 测试图片的文件名\r\n\r\n        if not os.path.exists(os.path.join(args.result_dir, set_cur)):  # 未找到保存文件的路径，则创造路径\r\n            os.mkdir(os.path.join(args.result_dir, set_cur))\r\n        psnrs = []  # 计算psnr与ssim的数组\r\n        ssims = []\r\n\r\n        for im in os.listdir(os.path.join(args.set_dir, set_cur)):  # 返回指定的文件夹包含的文件或文件夹的名字的列表\r\n            if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\r\n                # 判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False\r\n                x = np.array(imread(os.path.join(args.set_dir, set_cur, im)), dtype=np.float32) / 255.0\r\n                # 读入文件，float32位，得到后每个数/255,归一化\r\n                #  dtype:数组中的数据类型\r\n\r\n                np.random.seed(seed=0)  # for reproducibility 随机数种子\r\n                y = x + np.random.normal(0, args.sigma / 255.0, x.shape)   # 从正态（高斯）分布中抽取随机样本\r\n                # 分布的均值（中心）0，分布的标准差（宽度）噪声级别/255 输出值的维度。为X的维度\r\n                # Add Gaussian noise without clipping\r\n                y = y.astype(np.float32)  # 转换数据类型 float32位\r\n                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\r\n                # 创建张量，维度 1 1 481 321\r\n                # view重构维度\r\n                torch.cuda.synchronize()  # 等待当前设备上所有流中的所有核心完成\r\n                start_time = time.time()  # 计算代码运行时间\r\n                # ceshi = y_.nelement\r\n                # ceshi2 = y_.squeeze(2)\r\n                # ceshi = y.size\r\n                if y.size < 154402:  # 图片较小，用GPU测试\r\n                    y_ = y_.cuda()\r\n                    x_ = model(y_)  # 使用模型对y_进行处理，输出x_\r\n                    # inference\r\n                else:   # 图片较大，用GPU测试\r\n                    x_ = model_cpu(y_)\r\n                x_ = x_.view(y.shape[0], y.shape[1])  # 把x_维度处理为二维\r\n                x_ = x_.cpu()  # 将变量放在CPU上\r\n                x_ = x_.detach().numpy().astype(np.float32)  # 整理为float32 数组 阻断反向传播\r\n                torch.cuda.synchronize()\r\n                elapsed_time = time.time() - start_time\r\n                print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\r\n\r\n                psnr_x_ = compare_psnr(x, x_)  # 比较 原图 与 加噪声再去噪的图 计算psnr\r\n                ssim_x_ = compare_ssim(x, x_)\r\n\r\n                # ssim_x_ = compare_ssim(x, x_)\r\n\r\n                # if args.save_result:\r\n                name, ext = os.path.splitext(im)  # 文件名 后缀\r\n                # show(np.hstack((y, x_)))  # show the image\r\n                save_result(x_, path=os.path.join(args.result_dir, set_cur,\r\n                                                  name + '_dncnn' + ext))\r\n                # save the denoised image  矩阵 ， 路径\r\n                psnrs.append(psnr_x_)\r\n                ssims.append(ssim_x_)\r\n        psnr_avg = np.mean(psnrs)\r\n        ssim_avg = np.mean(ssims)\r\n        psnrs.append(psnr_avg)\r\n        ssims.append(ssim_avg)\r\n        if args.save_result:\r\n         save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\r\n        log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/test.py b/test.py
--- a/test.py	
+++ b/test.py	
@@ -1,5 +1,8 @@
 # 官方库
-import torch, os, time
+import os
+import time
+import torch
+
 os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
 import numpy as np
 from imageio import imread
@@ -8,11 +11,9 @@
  # 私人库
 
 from public import parse_args, log
-from data_process import show, save_result
+from data_process import save_result
 from model import DnCNN
 
-
-
 if __name__ == '__main__':
     # 参数
     args = parse_args(1)  #测试集
@@ -99,12 +100,13 @@
                 save_result(x_, path=os.path.join(args.result_dir, set_cur,
                                                   name + '_dncnn' + ext))
                 # save the denoised image  矩阵 ， 路径
-                psnrs.append(psnr_x_)
+                psnrs.append(psnr_x_)  # 向列表末尾添加元素
                 ssims.append(ssim_x_)
-        psnr_avg = np.mean(psnrs)
+        psnr_avg = np.mean(psnrs)  # np.mean求平均值
         ssim_avg = np.mean(ssims)
         psnrs.append(psnr_avg)
         ssims.append(ssim_avg)
-        if args.save_result:
-         save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))
+        # if args.save_result:
+        save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))
+        # 以文本形式 保存每一张图片的PSNR与SSIM结果
         log('Datset: {0:10s} \n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))
